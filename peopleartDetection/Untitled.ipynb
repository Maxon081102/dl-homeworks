{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c31e20-16ab-456e-a791-c4a3883d6915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as L\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b6cfdd-f393-4444-ac62-5232838bd36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import PeopleArtModel\n",
    "from module import PeopleArtModule\n",
    "from imgData import ImgDatamodule, ImgData\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df48998c-d5ea-4aa6-886e-fea3bef484b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(every_n_train_steps=10)\n",
    "early_stopping = EarlyStopping(monitor=\"val_map\", mode=\"max\", patience=10)\n",
    "callbacks = [checkpoint_callback, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d21036-333e-42c5-ab86-339907f9f24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(project = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a22270f-8268-40a9-b450-6d7e24b9caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeopleArtModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e0dcddc-8d97-42d9-9932-e1baf96d7301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitinmaxim/miniconda3/envs/dl/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    }
   ],
   "source": [
    "module = PeopleArtModule(model, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "336fe8ca-98a2-48d9-8ab5-aa48595fba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImgDatamodule(32, model.get_data_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15e12f27-7017-4bf9-ad36-b65282bc4c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/nikitinmaxim/miniconda3/envs/dl/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    callbacks=callbacks,\n",
    "    logger = wandb_logger,\n",
    "    max_epochs=100,\n",
    "    limit_train_batches=100,\n",
    "    limit_val_batches=100,\n",
    "    overfit_batches=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e09bd6-cf8b-4bc4-b35e-337f81ffb27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnikitinm117\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c0e3ea568b41f5b3092fbcc668ee5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011170337955829585, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20231121_190803-0nw2spnc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nikitinm117/test/runs/0nw2spnc' target=\"_blank\">fluent-pond-3</a></strong> to <a href='https://wandb.ai/nikitinm117/test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nikitinm117/test' target=\"_blank\">https://wandb.ai/nikitinm117/test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nikitinm117/test/runs/0nw2spnc' target=\"_blank\">https://wandb.ai/nikitinm117/test/runs/0nw2spnc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name        | Type                 | Params\n",
      "-----------------------------------------------------\n",
      "0 | model       | PeopleArtModel       | 36.3 M\n",
      "1 | val_metrics | MeanAveragePrecision | 0     \n",
      "-----------------------------------------------------\n",
      "36.1 M    Trainable params\n",
      "225 K     Non-trainable params\n",
      "36.3 M    Total params\n",
      "145.328   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitinmaxim/miniconda3/envs/dl/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/nikitinmaxim/miniconda3/envs/dl/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 10. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/nikitinmaxim/miniconda3/envs/dl/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:268: You requested to overfit but enabled train dataloader shuffling. We are turning off the train dataloader shuffling for you.\n",
      "/Users/nikitinmaxim/miniconda3/envs/dl/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/nikitinmaxim/miniconda3/envs/dl/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949c3b59651b469bb42848d8e8b900ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitinmaxim/miniconda3/envs/dl/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model=module,\n",
    "    datamodule=data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6e4629-c54b-40e4-b159-d4556fb5fd11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1a918-b135-4151-8f35-a6d9c08693e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
